<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="behavioral data collection, mechanical turk, psychology">
    <meta name="author" content="todd m. gureckis">


    <title></title>
    <script src="http://code.jquery.com/jquery-1.10.1.min.js"></script> 
    <script src="http://d3js.org/d3.v3.min.js" charset="utf-8"></script>
    <script src="js/remark.js" type="text/javascript"></script>


    <!-- Bootstrap core CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/cdbo.css" rel="stylesheet">


  </head>
  <body>
    <textarea id="source">
name: title
class: center, middle


# The Internet as Psychology Lab
<hr>
.author[
**Todd Gureckis** ([@todd_gureckis](http://twitter.com/todd_gureckis))

and the
_[Computation and Cognition Lab](http://gureckislab.org)_, et al.

_New York University_  
]


???
Hi, and thanks for the opportunity to speak to
such an interesting and interdisciplinary group of people.
One of the challenges of communicating with such diverse
groups is coming to the initial common ground about
approaches, assumptions, and goals.
So before I begin, I believe the best thing to do 
is to introduce myself a little bit.
As Bob said, I hail from the world of psychology and cognitive science,
more specifically from New York University where I am an 
associate professor of psychology.  

---

class: center, middle

<img src="images/goddambell.jpg" width="500">

???

Since I am working in psychology, I am allowed to make psychology
jokes because they come at my own expense.  When I tell most people,
including my family, that I am a psychologist, they seem to naturally
assume that I am working on the clinical side of the field, and
imagine that my days are spent with patients on a couch.  For many
years, I wrestled with the right way to summarize what my
type of psychological research involved in a way that wouldn't
put people to sleep.

and i've since come up with what I think it a pretty snappy
summary.  

In particular, my research starts with the assumption
that the human mind is an information processing device.  The 
goal of my research is to build a more complete understanding 
of this device in terms of computational models.

---

class: center, middle

# Where human and machine learning meet

<img src="images/humanandmachine.png" width="700">

???

The situation is analogous to trying to build a (software) robot which you
hope will act as similarly as possible to a human.  To do this
I oscillate back and forth between careful empirical studies
of human psychology to understand the ways in which people think
and reason, and the engineering side which constructs computational
models that act similarly.

---

class: center, middle

# Where human and machine learning meet

<img src="images/humanandmachine2.png" width="700">

???


In my talk in the psychology department on Monday, I spoke
about some of the work exploiting this approach particular in
application to understanding self-directed or self-guided learning
behavior, but today I wanted to focus a bit more specifically 
on the empirical and methodological side of my research.

---

class: center, middle

<img src="images/goddambell.jpg" width="500">

???

Now the naive conception of how I spend my day that
exists in the mind of my family members is incorrect
mostly in content -- if there is a couch, it is most
likely occupied by a sleeping, overworked graduate student
than a traditional patient.  However, is it not incorrect
in the higher-order generalization that
a lot of psychological research follows particular
stereotypic models of human interaction.


---

class: center, middle

<img src="images/pavlov_conditioning_dogs2.gif" width="500">

???

early experimental approaches to the study of behavior
which are familiar to most people might involve studies of
basic learning phenomena in animals such as pigeons or dogs

---

class: center, middle

<img src="images/hilgardexp2_sepia.jpg" width="500">

???

which was later replaced with studies of learning or
thinking that were done with subjects in a lab using
pen and paper or through structured interviews and
observations of behavior in the context of some task.

---

class: center, middle

<img src="images/PBS2.jpg" width="500">

???

which today might looks something like this, where
a subject interacts with information presented on
a computer display, where scientists might control
aspect of the information presented and record
behavioral responses using a keyboard or mouse along
with eye fixation data, reaction time, or even
neural correlates like EEG and fMRI.

What has remained relatively unchanged across all these
subsequent versions is the overall context in which the
research takes place: namely laboratories on college campuses,
and in the case of human research, the population which is
tested is most often college aged undergraduates.

---

class: center, middle

# What's next?
## &nbsp;


???

the central topic my talk to day is basically to
ask, what's next?  What will -- particular experimental
as opposed to observational -- psychological research look 
like in coming years?  

---

class: center, middle

<img src="images/600px-Internet_map_4096.png" width="400">

## .blue[The Internet as Psychology Lab]

???

And what I believe is becoming somewhat clear is that
the answer will be is some variant on the title of my
talk, that is The Internet at Psychology Lab.

The goal of my work in this area
has been to try to explore the boundaries of what 
research might look like, as well as to help enable
these advances through software engineering projects
and tool building.


---

class: middle

# Overview of talk

1.  How does psychology research conducted on the Internet compare
to that of the traditional lab?
2.  What are the technical challenges that researchers face in
conducting experimental research online?
3.  .blue[psiTurk] - an open platform for science on Amazon Mechanical Turk
4.  Future possibilities for psychological research on the Internet

---

class: middle

.left-column[

<img src="images/Computer_Workstation_Variables.jpg" width="300">
]

.right-column[
# typical laboratory-based experiment
<hr>

1. Office-style interaction
1. General control over lighting, temperature, viewing angle, distance
1. A few people at a time (1-5/hour), each on individual workstations
1. Data saved to local disc or to a local file server
]

???

---


class: middle


.left-column[
.center[
<img src="images/womenonlaptop.jpg" width="200"><img src="images/TabletUser.jpg" width="200">
<img src="images/smartphone.jpg" width="200"><img src="images/OutsideUser.jpg" width="200">
]
]

.right-column[
# typical online experiment
<hr>

1. Experiments delievered using a web-browser
1. Variable lighting, conditions, computer system, etc...
1. International subject pool
1. Many people at the same time (10-100/hour), each talking to a centralized server
1. Data saved in database to allow concurrent reading/writing


]

???

These difference contribute both methodological complications
for research (e.g., introducing noise or confounding variables)
but also introduces significant technical challenges for the
average researcher.

---


class: center, middle

# How does online data compare to that collected in the lab?

---

# Amazon Mechanical Turk


- Developed by [Amazon.com](http://amazon.com)

- Originally for in-house use to detect duplicate product postings on Amazon's site .red[*]

<br><br>
.center[<img src="images/AMTLogo.png" width="300">
]



.footnote[.red[*] Nice summary in the [New York Times](http://www.nytimes.com/2007/03/25/business/yourmoney/25Stream.html)]


# Key terminology


- **HIT** = Human Intelligence Task (a unit of work, e.g. a trial or an entire sequence of trials in an experiment)

- .orange[**Requester**] = an entity (e.g., researcher) who posts HITs

- .blue[**Worker**] = a person who performs the task


---

# What kinds of tasks?

- Difficult for computer or machine learning systems
    - Provide three key words to describe an image
    - Does this photograph contain a car?
    - What event does this twitter search refer to?
    
- Traditional work
    - Write a positive review for this product online 
    - Translate this text from English to Spanish
    

- .green[Help with science!]
    - **Participate in my human cognition/perception/learning experiment!**


---

# Who are the workers?

- 46.80% US, 34% India, 19.20% Other

- United States demographic
    - 55-65% female
    - Most make  <$60k/year
    - Median age of 30
    - Hold bachelor's and are young
    - Distribution mostly similar to US internet pop.
    
- See Ipeirotis, et al. (2010) or Mason and Siddharth (2011).

---

# Why use AMT-based experiments?

- **Convenient**  Eaiser than recruiting using email lists/forums
- **Fast**  Collect a lot of data quickly, also good for piloting
- **Affordable** Workers will sign up for $2.00 for 15-25 minute session
- **Anonymous** Subject never meets experimenter
- **Replicable** Very easy to share your experiment code


---

# Why not?
Numerous concerns have been raised about AMT data:
<br>

- **Selection Bias:** No control over who takes the experiment
    - 53% are self-identified liberals, 25% conservatives, 73% voted for Obama, see details [here](http://themonkeycage.org/2012/12/19/how-representative-are-amazon-mechanical-turk-workers)
    - Makes AMT sample probably less useful for research on ideology, or political attitudes (see [this](http://www.culturalcognition.net/blog/2013/7/10/fooled-twice-shame-on-who-problems-with-mechanical-turk-stud.html) blogpost for a discussion)

    - On the other hand, 20 year old university students are a very special sample too!

- **Population size:** 
    - Amazon claims 0.5 million registered users
    - Effective population size of about 8000-10000 users

---

# Why not?

- **Contamination of subject base** 
    - Recent [study](http://www.jessechandler.com/uploads/2/8/0/5/2805897/13_chandler_mueller__paolacci.pdf) has addressed this question
    - Can be a problem for *very* widely used paradigms 
      - 56% had participated in Prisoner's Dilemma, 52% in Ultimatum game, 30% Trolley problem

    - Cross talk (e.g. in AMT forums) seems to be more and more common (workers share information about payment, duration, etc.)

    - For specific studies repeated participation can be prevented by recording worker's IDs

---

# Why not?
- **Non-lab setting **
    - [This](http://www.jessechandler.com/uploads/2/8/0/5/2805897/13_chandler_mueller__paolacci.pdf) study showed
      - 27% were not alone while working on the HIT
      - 18% were watching tv
      - 14% were listening to music

    - Recording how often participants change windows/take breaks might help clean data

    - Still, the lack of experimental control over a worker's environment might make some studies unsuitable for AMT




---

name: replicationstudies

# Lots of interest in this...

.refs[

- Gosling, S.D., Vazire, S., Srivastava, S., & John, O.P. (2004). [Should we trust web-based studies? A comparative analysis of six preconceptions about Internet questionnaires](http://ww.w.simine.com/docs/Gosling_et_al_AP_2004.pdf). _American Psychologist_, 59, 2, 93-104.

- Paolacci, G., Chandler, J., & Ipeirotis, P. G. (2010). [Running experiments on Amazon Mechanical Turk](http://repub.eur.nl/res/pub/31983/jdm10630a[1].pdf). _Judgment and Decision Making_, 5, 411-419.

- Buhrmester, M., Kwang, T., & Gosling, S. D. (2011). [Amazon's Mechanical Turk A New Source of Inexpensive, Yet High-Quality, Data?](http://pps.sagepub.com/content/6/1/3.full). _Perspectives on Psychological Science_, 6(1), 3-5.

- Germine, L., Nakayama, K., Duchaine, B.C., Chabris, C.F., Chatterjee, G. & Wilmer, J.B. (2012).  [Is the Web as good as the lab?  Comparable performance from Web and lab in cognitive/perceptual experiments](http://www.springerlink.com/content/f0244t772070138w/)  _Psychonomic Bulletin & Review_,  19.5.


- Shapiro, D. N., Chandler, J., & Mueller, P. A. (2013). [Using Mechanical Turk to Study Clinical Populations](http://s3.amazonaws.com/academia.edu.documents/30554524/Clinical_Psychological_Science-2013-Shapiro-2167702612469015.pdf?AWSAccessKeyId=AKIAIR6FSIMDFXPEERSA&Expires=1374090987&Signature=%2B4nErhKWOQhoWYY9gpgV0EbvVa0%3D&response-content-disposition=inline). _Clinical Psychological Science_, 1(2), 213-220.

]

---


# Do classic findings replicate?

- Some members of our lab recently contributed to this study that tested some classic psychology experiments on AMT.red[*]

    - Crump, M. J., McDonnell, J. V., & Gureckis, T. M. (2013). [Evaluating Amazon's Mechanical Turk as a tool for experimental behavioral research.](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0057410) PloS one, 8(3).


- Focus was on reaction time findings that require sustained attention from subjects, precise recording of responses, learning experiments involving more cognitive effort 


.footnote[.red[*] For a summary of the paper see this [blog post](http://gureckislab.org/blog/?p=1297)]

---


# Stimulus Detection
.left-column[ 

Stroop

  - People respond faster to congruent (e.g. .blue[blue]) than to incongruent (.green[blue]) items


Task Switching

  - Faster RT if task stays the same (e.g. "Odd or Even?") than when tasks alternate ("Odd or Even?" / "Small or Large?")

Flanker

  - When identifying a target (e.g. "h"), congruent flankers ("hhhhh") lead to faster RTs than incongruent ("fffhff") ones

]
  

.center[.right-column[
<img src="images/StroopResult.png" width="160">
<img src="images/TaskSwitchingResult.png" width="160">
<img src="images/FlankerResult.png" width="160">
]]  


---

# Stimulus Detection
.left-column[ 

Simon

  - Targets that are spatially compatible with response key are identified faster


Visual Cuing 

  - Stimulus detection is faster for cued  versus uncued targets if cue is presented after short interval (<=300ms) and slower after longer interval (>=400ms)

Attentional Blink

  - During rapid serial visual presentation visual target detection is impaired if target is displayed 100-500ms after another one


]


.center[.right-column[
<img src="images/SimonResult.png" width="160">
<img src="images/ContCueing.png" width="160">
<img src="images/AttentionalBlink.png" width="160">
]]  

---


# Subliminal Perception

Masked priming

  - Responding to arrow probes that are either compatibly (prime: >>, probe: >>) or incompatibly primed (prime: <<, probe: >>) at durations of 16, 32, 48, 64, 80, and 96 ms 

  -  Previous finding was that compatibility effects are negative for very short prime durations and positive for longer ones


  .center[
   <img src="images/PrimingResult.png" width="330">
   ]

  - Only partially replicated: no negative compatibility effect

  - Possibly lower bound on display duration in browser!

---


# Category Learning

- Classic Shepard, Hovland, & Jenkins (1961) paper

- Six different ways of classifying the same 8 items (geometric figures with 3 binary dimensions) into deterministic categories

- Generally Type I is learned faster than Type II which is faster that Types III-V, with Type VI the hardest
.center[
<img src="images/abstractstructureSHJ.png" width="150"><img src="images/dimstructureSHJ.png" width="170">
<img src="images/SHJDifficulty.png" width="550">
]

---

# Results

Although type I was learned easily, performance on all other types was significantly worse than in the original study
<br><br>

.center[
<img src="images/exp8-nosofsky.png" height="290"><img src="images/exp8-amt.png" height="290">
]


---


# Incentives too low?
There was little difference between high ($2 to $4.50 with bonus), medium ($1.50), and low-payment ($.75) groups
<br><br>

<img src="images/exp9-typeII.png" height="290">
<img src="images/exp9-typeIV.png" height="290">


---


# Bad instructions?
Including manipulation checks that asked non-trivial questions about the task improved performance on types II to VI
<br><br>

.center[<img src="images/exp10-l-vs-amt.png" height="310">]


---

# Replication in other Areas

1. Clinical (Shapiro, et al, 2013)

  - Scores on a range of psychometric tests had high internal consistency and test-retest reliability  (r =.87)

2. Personality (Buhrmeser, et al, 2011)

  - No difference in consistency on personality questionnaires at different payment levels, and absolute levels of consistency and test-retest reliability were high (r = .88)

3. JDM (Paolacci, et al, 2010)
  
  -  Compared classic JDM studies (Asian Disease, Linda, Physicians Problem) on AMT and university subject pool
  - No difference in failure rate of catch trials and pattern of behavior in studies but AMT subjects were more risk averse

---

# A word on Ethics

- How much should researchers pay?  
    - As much as the market supports or should it match what you pay in the lab (roughly)?
    - AMT has been criticized for incentivizing companies to outsource labor without adequate compensation (for discussions see for example [here](http://priceonomics.com/who-makes-below-minimum-wage-in-the-mechanical/?utm_source=buffer&utm_campaign=Buffer&utm_content=buffer2d486&utm_medium=twitter), [here](http://economix.blogs.nytimes.com/2013/03/18/the-unregulated-work-of-mechanical-turk/), and [here](http://www.huffingtonpost.com/julian-dobson/mechanical-turk-amazons-underclass_b_2687431.html))

- Can researchers get IRB approval for your experiment?
    - Arguably, workers have more freedom of choice than lab participants (can stop experiment any time)
    - Wasn't very difficult to add to an existing IRB at NYU
    - Common at many, many universities now.

---

# Being a good requester
- If your task breaks, workers *will* e-mail!

- They also share information about good and bad requesters:
<br><br>
.center[
<img src="images/Turkopticon.png" height="350">
]
 
---

# Be a good requester
 
A few recommendations to keep workers happy...

1. Before running, .blue[test your experiment] on different browsers and the sandbox (AMT's testing environment)

1. Give explicit instructions and .blue[show warnings] about closing the page, going back in the browsers, etc.

1. Start collecting data in .blue[small batches]
 
1. If something goes wrong, provide an .blue[alternative payment method] for workers who are unable to finish or submit HIT
    - One way of doing this is to provide a HIT with no content specifically aimed at workers that had problems and pay them using a "bonus"
 
---


# Summary

1. AMT allows researchers to collect data quickly and conveniently

1. Web experiments can prevent experimenter effects and increase anonymity

1. Many classic psychology findings replicate with high fidelity
    - But it's important to check for browser limits regarding presentation time, etc.

    - It's also helpful to check participants' understanding of the task

1. Changing payment does not have a large effect performance but does affect signup and dropout rates

1. Online reputation matters!  
    
---

class: middle
 
# What are researcher's **attitudes** about online studies?

- March - April 2014 we conducted a survey of researchers working in the 
behavioral sciences
- Responses solicited through bulletin boards, mailing lists, and other social
media outlets
- Including 201 responses

---

class: center, middle

# What is your main area of work?

<br>
<img src="images/chart-1.png" height="200">

---

class: center, middle

# Have you collected behavioral data online in your lab?

<br>
<img src="images/chart-2.png" height="200">


---

class: center, middle

# What are the major **challenges** in using behavioral data collected online in research?

<br>
<img src="images/chart-3.png" width="500">

---

class: center, middle

# What are the major **benefits** in using behavioral data collected online in research?

<br>
<img src="images/chart-4.png" width="500">

---

class: center, middle

# When reviewing a paper with data collected online in my area (e.g., Mechanical Turk):

<br>
<img src="images/chart-5.png" width="500">

---

class: center, middle

# If you were to use online data in your research, what role would it primarily play?

<br>
<img src="images/chart-6.png" width="500">

---

class: center, middle

# If you were required to run an online experiment tomorrow what tool would you use?

<br>
<img src="images/chart-7.png" width="500">

---

class: center, middle

# Would you be interested in a software tool that helped simplify online data collection?

<br>
<img src="images/chart-8.png" width="500">

---

class: 

# What features of such a system you would find appealing/useful?

<br>
<img src="images/chart-9.png" width="770">

---

class: center, middle

<img src="images/psiturklogo_caption.png" width="730">

---

class: center, middle


<img src="images/what_is_1.png" width="730">

---

class: center, middle


<img src="images/what_is_2.png" width="730">

---

class: center, middle


<img src="images/what_is_3.png" width="730">

---

class: center, middle


<img src="images/what_is_4.png" width="730">

---

class: center, middle


<img src="images/what_is_5.png" width="730">

---

# Architecture

- **Command line tool** (this is the "player")
  - Allows you run experiments from a computer of your choosing
  - Allows you to interact with AMT to pay people, assign bonuses

- **psiturk.org Cloud-based services** 
  - provides secure hosting (Ad Server)
  - experiment exchange (system for sharing experiments between researchers)

---

class: center, middle


<img src="images/cloud_1.png" width="730">

---

class: center, middle


<img src="images/cloud_2.png" width="730">

---

class: center, middle


<img src="images/cloud_3.png" width="730">

---

class: center, middle


<img src="images/cloud_4.png" width="730">

---

class: center, middle


<img src="images/cloud_5.png" width="730">

---

class: center, middle

<img src="images/cloud_6.png" width="730">

---

class: center, middle


<img src="images/cloud_7.png" width="730">

---


class: center, middle

### .gray[Checkout psiturk.org, documentation, hands-on psiturk demo]

---

class:

# Key Advantages 

- Open source code base
- Exchangeable experiments (helps students learn, helps replicability)
- Enables complex designs that offload computation onto server rather than client

---


class: center, middle


# psiTurk by the numbers
<img src="images/psiturknumbers.png" width="580">

---


class: center, middle


<img src="images/workdistribution.png">

---


class: center, middle


<img src="images/experimentsizes.png">

---

class: middle


# Future directions for psiTurk

- Enabling other recruitment gateways beside Mechanical Turk
(e.g., lab-based studies, studies using mobile devices)
- Providing API hooks that enable researchers to query a potential
worker and see if they may have been exposed to a similar manipulation
in a previous psiTurk task
- Cloud-based hosting of experiments
- Exposing the command line elements as a python API which would
enable adaptive experiment designs
- Multi-player, multi-participant experiments

---

class: middle


# Is AMT "overfished"?

- Our own data viewed only from psiTurk suggest there are a lot of
"expert workers" on AMT
- AMT workers may actually be among the most heavily studied participant
group in human history (behind university undergraduates)
- The pay-for-work environment on AMT may be counter-productive
  - extrinsic rewards can emphasize "sufficent" work rather than "good" work
- AMT population is not that variable

---

class: middle

<img src="images/knowzio.png" width="750">

# The Knowzio Project 
## with Anna Coenen (NYU Psych) and Panos Ipeirotis (NYU Stern)

---

class: middle

# The Knowzio Project 

- Simple surveys and cognitive tests presented as fun quizes:

<img src="images/knowzioquiz.png" width="750">

---

class: middle

# Internet Advertising as a Tool for Psychology Research

- The Google platform has over 1 billion worldwide users
- Wide range of individuals in varying traits, personalities, etc...
- Ad appears like this on different websites:

<center>
<img src="images/knowzioad.png" width="300">
</center>

---

class: 

# Cost/Efficiency

- 10 Question survey about US politics
- Roughly $0.60 per completed survey paid to AdWords (participants are free)
- 13 days, $30.00/day ad budget:
  - 848 "converted clicks" (meaning people who completed some or all of the survey)
  - 641 complete survey completions

---
class: 

# Targetting recuitment

In many studies, you want to reach particular demographics or subgroups.
For example, you might want to compare experts versus non-experts on some
cognitive task

- How to find these people?
  - AMT is not a good option... unlikely to find experts for particular content
  - A lot of effort to manually solicit experts via specialist mailing lists, blogs, etc...
- One idea: Use the advanced targetting features of Internet advertising platforms (Ipeirotis and Gabrilovich, 2014)!

---
class: 

# Conversion Tracking

- In advertising speak a "conversion" is when someone who clicks on your ad
does something on your website
- Could be anything:
  - sign up for mailing list
  - hover mouse over an image
  - **purchase something on ecommerce site**

---

# Conversion Optimizer
- Attempts to automatically adjust bids (and therefore where the ad appears)
to optimize converison rate
<center>
<img src="images/conversionoptimizer.png" width="600">
</center>

---

# An Experiment

- Separately optimze two campaigns which captures liberals versus 
conservatives, without specific keyword or domain targetting (i.e., let the 
Google system learn)
- A simple 10 question survey (5 about political beliefs)
- If clicked on ad associated with "liberal" counts up the number of
liberal answers you gave.  If clicked on ad associate with "conversative" vice
versa.
- Otherwise all settings were identical including keywords, budgets, bidding
strategies, etc... 

<center>
<img src="images/immigrantquestion.png" width="400">
</center>

---

# Some preliminary results

<center>
<img src="images/prelimresultsadwords.png" width="750">
</center>

---

# How it gets there

Google optimizes the conversion rate, which will be higher
for sites where people get relatively high scores according
to our scheme (11 would be answering conservative/liberal on every question).
<br><br>
<center>
<img src="images/conservativewebsite.png" width="600">
</center>
<br><br>
Preliminary data, generally sparse so hard to see exactly how this
will play out across many websites

---

# Future Questions

- How costly is this for complete psychology studies (comparable to the kinds we've
run on AMT)?
- How does the data compare from this method to the AMT one?
- What types of psychological or individual difference variables can you optimize
for?
- *BTW* - Google provides up to $10K of credits on AdWords to certified non-profit entities

---

# Summary

- For many psychologists the Internet is the Lab
- An exciting time for exploring new methods and techniques for Internet recruitment
in research studies
- Five years ago better to work in a research lab at Google/Facebook (more data) but
tools are increasingly available for large scale experiments conducted within academic
research budgets
- Important role of tool building in facilitating best research practices and facilitating
replication/open science.

---

class: center, middle
#Thanks!!

    </textarea>
    <script type="text/javascript">

      function getSearchParameters() {
            var prmstr = window.location.search.substr(1);
            return prmstr != null && prmstr != "" ? transformToAssocArray(prmstr) : {};
      }

      function transformToAssocArray( prmstr ) {
          var params = {};
          var prmarr = prmstr.split("&");
          for ( var i = 0; i < prmarr.length; i++) {
              var tmparr = prmarr[i].split("=");
              params[tmparr[0]] = tmparr[1];
          }
          return params;
      }

      var params = getSearchParameters();

      // this loads the markdown slide content from a file
      // $.ajaxSetup({async:false});
      // $("#source").load("slides.md");
      var slideshow = remark.alloc();
      slideshow.start();

    </script>

  </body>
</html>
